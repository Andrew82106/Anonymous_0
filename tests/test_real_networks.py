
import sys
import os
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..'))

import bnlearn as bn
import pandas as pd
import numpy as np
import json
from utils_set.causal_reasoning_engine import CausalReasoningEngine
from utils_set.utils import ConfigLoader, path_config

# ä¼ ç»Ÿå› æœå‘ç°ç®—æ³•
try:
    from pgmpy.estimators import PC, HillClimbSearch, BicScore
    from pgmpy.base import DAG as PgmpyDAG
    PGMPY_AVAILABLE = True
except ImportError:
    PGMPY_AVAILABLE = False
    print("Warning: pgmpy not available. Traditional baselines will be skipped.")

# è®¾ç½®ç»“æœä¿å­˜è·¯å¾„ï¼ˆä½¿ç”¨è·¯å¾„é…ç½®ï¼‰
RESULTS_FILE = str(path_config.real_network_results_file)

def compute_shd(true_adjmat, pred_adjmat):
    """
    è®¡ç®—ç»“æ„æ±‰æ˜è·ç¦» (Structural Hamming Distance)
    
    Args:
        true_adjmat: çœŸå®é‚»æ¥çŸ©é˜µ (pandas DataFrame or numpy array)
        pred_adjmat: é¢„æµ‹é‚»æ¥çŸ©é˜µ (pandas DataFrame or numpy array)
    
    Returns:
        int: SHD å€¼ï¼ˆå·®å¼‚è¾¹çš„æ•°é‡ï¼‰
    """
    if isinstance(true_adjmat, pd.DataFrame):
        true_adjmat = true_adjmat.values
    if isinstance(pred_adjmat, pd.DataFrame):
        pred_adjmat = pred_adjmat.values
    
    return int(np.sum(np.abs(true_adjmat - pred_adjmat)))

def run_pc_algorithm(df, alpha=0.05):
    """
    è¿è¡Œ PC ç®—æ³•ï¼ˆä¼ ç»Ÿ Baselineï¼‰
    
    Args:
        df: æ•°æ®é›†
        alpha: æ˜¾è‘—æ€§æ°´å¹³
    
    Returns:
        é‚»æ¥çŸ©é˜µ (numpy array)
    """
    if not PGMPY_AVAILABLE:
        return None
    
    try:
        pc = PC(data=df)
        model = pc.estimate(significance_level=alpha)
        
        # è½¬æ¢ä¸ºé‚»æ¥çŸ©é˜µ
        nodes = sorted(df.columns)
        n = len(nodes)
        adjmat = np.zeros((n, n))
        
        for edge in model.edges():
            source_idx = nodes.index(edge[0])
            target_idx = nodes.index(edge[1])
            adjmat[source_idx, target_idx] = 1
        
        return adjmat
    except Exception as e:
        print(f"PC algorithm failed: {e}")
        return None

def run_hillclimb_algorithm(df):
    """
    è¿è¡Œ HillClimb ç®—æ³•ï¼ˆä¼ ç»Ÿ Baselineï¼‰
    
    Args:
        df: æ•°æ®é›†
    
    Returns:
        é‚»æ¥çŸ©é˜µ (numpy array)
    """
    if not PGMPY_AVAILABLE:
        return None
    
    try:
        hc = HillClimbSearch(data=df)
        model = hc.estimate(scoring_method=BicScore(data=df))
        
        # è½¬æ¢ä¸ºé‚»æ¥çŸ©é˜µ
        nodes = sorted(df.columns)
        n = len(nodes)
        adjmat = np.zeros((n, n))
        
        for edge in model.edges():
            source_idx = nodes.index(edge[0])
            target_idx = nodes.index(edge[1])
            adjmat[source_idx, target_idx] = 1
        
        return adjmat
    except Exception as e:
        print(f"HillClimb algorithm failed: {e}")
        return None

def run_random_baseline(n_nodes, n_edges):
    """
    ç”Ÿæˆéšæœºå›¾ï¼ˆRandom Baselineï¼‰
    
    Args:
        n_nodes: èŠ‚ç‚¹æ•°é‡
        n_edges: è¾¹æ•°é‡
    
    Returns:
        é‚»æ¥çŸ©é˜µ (numpy array)
    """
    adjmat = np.zeros((n_nodes, n_nodes))
    
    # éšæœºç”Ÿæˆ n_edges æ¡è¾¹ï¼ˆé¿å…è‡ªç¯ï¼‰
    edges_added = 0
    attempts = 0
    max_attempts = n_edges * 10
    
    while edges_added < n_edges and attempts < max_attempts:
        i = np.random.randint(0, n_nodes)
        j = np.random.randint(0, n_nodes)
        
        if i != j and adjmat[i, j] == 0:
            adjmat[i, j] = 1
            edges_added += 1
        
        attempts += 1
    
    return adjmat

def test_network(network_name, engine, sample_size=1000, test_all_edges=True):
    """
    æµ‹è¯•å•ä¸ªè´å¶æ–¯ç½‘ç»œï¼ˆå®Œæ•´å¯¹æ¯”ç‰ˆï¼‰
    
    Args:
        network_name: ç½‘ç»œåç§°
        engine: å› æœæ¨ç†å¼•æ“
        sample_size: é‡‡æ ·æ•°é‡
        test_all_edges: æ˜¯å¦æµ‹è¯•æ‰€æœ‰è¾¹ï¼ˆTrue=å®Œæ•´SHDï¼ŒFalse=é‡‡æ ·è¾¹è®¡ç®—å‡†ç¡®ç‡ï¼‰
    """
    print(f"\n{'='*60}")
    print(f"Testing Network: {network_name}")
    print(f"{'='*60}")
    
    # 1. åŠ è½½ç½‘ç»œå’Œé‡‡æ ·æ•°æ®
    try:
        dag = bn.import_DAG(network_name)
        df = bn.sampling(dag, n=sample_size, verbose=0)
    except Exception as e:
        print(f"Error loading network {network_name}: {e}")
        return None

    print(f"Data: {df.shape[0]} samples, {df.shape[1]} variables")
    print(f"Variables: {list(df.columns)}")
    
    # 2. æå–çœŸå®å› æœå›¾ (Ground Truth)
    true_adjmat = dag['adjmat']
    nodes = list(true_adjmat.index)
    n_nodes = len(nodes)
    
    edges = []
    for source in true_adjmat.index:
        for target in true_adjmat.columns:
            if true_adjmat.loc[source, target] == 1:
                edges.append((source, target))
    
    print(f"Ground Truth: {len(edges)} edges in DAG")
    
    # ============================================================
    # PART 1: LLM-based Blind Causal Discovery
    # ============================================================
    print(f"\n[1/4] Running LLM-based Blind Causal Discovery...")
    
    # åˆå§‹åŒ–é¢„æµ‹é‚»æ¥çŸ©é˜µ
    llm_adjmat = pd.DataFrame(
        np.zeros((n_nodes, n_nodes)),
        index=nodes,
        columns=nodes
    )
    
    pairwise_results = []
    correct_count = 0
    
    # é€å¯¹æµ‹è¯•ï¼ˆå…¨å›¾ï¼‰
    for source, target in edges:
        X = df[source].values
        Y = df[target].values
        
        try:
            analysis = engine.analyze_pair(X, Y)
            result = engine.infer_causality(analysis['narrative'])
            
            prediction = (
                result.get('direction') or 
                result.get('causal_direction') or 
                result.get('causal_direction_judgment') or
                'Unclear'
            )
            
            # æ ¹æ®é¢„æµ‹æ›´æ–°é‚»æ¥çŸ©é˜µ
            if prediction == "A->B":
                llm_adjmat.loc[source, target] = 1
                is_correct = True
                correct_count += 1
            elif prediction == "B->A":
                llm_adjmat.loc[target, source] = 1
                is_correct = False
            else:
                # Unclear: éšæœºçŒœæµ‹
                is_correct = False
            
            pairwise_results.append({
                'pair': f"{source}->{target}",
                'prediction': prediction,
                'is_correct': is_correct
            })
            
            status = "âœ…" if is_correct else "âŒ"
            print(f"  {status} {source}->{target}: {prediction}")
            
        except Exception as e:
            print(f"  âš ï¸  Error on {source}->{target}: {e}")
    
    llm_accuracy = correct_count / len(edges) if edges else 0
    llm_shd = compute_shd(true_adjmat, llm_adjmat)
    
    # ============================================================
    # PART 2: Traditional Baselines
    # ============================================================
    print(f"\n[2/4] Running PC Algorithm (Traditional Baseline)...")
    pc_adjmat = run_pc_algorithm(df)
    if pc_adjmat is not None:
        pc_adjmat_df = pd.DataFrame(pc_adjmat, index=nodes, columns=nodes)
        pc_shd = compute_shd(true_adjmat, pc_adjmat_df)
        print(f"  PC Algorithm SHD: {pc_shd}")
    else:
        pc_shd = None
        print("  PC Algorithm: FAILED or UNAVAILABLE")
    
    print(f"\n[3/4] Running HillClimb Algorithm (Traditional Baseline)...")
    hc_adjmat = run_hillclimb_algorithm(df)
    if hc_adjmat is not None:
        hc_adjmat_df = pd.DataFrame(hc_adjmat, index=nodes, columns=nodes)
        hc_shd = compute_shd(true_adjmat, hc_adjmat_df)
        print(f"  HillClimb SHD: {hc_shd}")
    else:
        hc_shd = None
        print("  HillClimb: FAILED or UNAVAILABLE")
    
    print(f"\n[4/4] Running Random Baseline...")
    random_adjmat = run_random_baseline(n_nodes, len(edges))
    random_adjmat_df = pd.DataFrame(random_adjmat, index=nodes, columns=nodes)
    random_shd = compute_shd(true_adjmat, random_adjmat_df)
    print(f"  Random SHD: {random_shd}")
    
    # ============================================================
    # PART 3: Comparison Report
    # ============================================================
    print(f"\n{'='*60}")
    print(f"ğŸ“Š COMPARISON REPORT - {network_name}")
    print(f"{'='*60}")
    print(f"Ground Truth Edges: {len(edges)}")
    print(f"\n{'Method':<25} {'SHD':<10} {'Accuracy':<15}")
    print(f"{'-'*60}")
    print(f"{'LLM (Blind)':<25} {llm_shd:<10} {llm_accuracy:.1%}")
    if pc_shd is not None:
        print(f"{'PC Algorithm':<25} {pc_shd:<10} {'N/A'}")
    if hc_shd is not None:
        print(f"{'HillClimb':<25} {hc_shd:<10} {'N/A'}")
    print(f"{'Random Guess':<25} {random_shd:<10} {'~50%'}")
    print(f"{'='*60}")
    
    if pc_shd is not None:
        improvement = pc_shd - llm_shd
        print(f"\nğŸ’¡ LLM vs PC: {improvement:+d} (Lower is better)")
    
    return {
        'network': network_name,
        'n_nodes': n_nodes,
        'n_edges': len(edges),
        'llm': {
            'shd': llm_shd,
            'accuracy': llm_accuracy,
            'pairwise_details': pairwise_results
        },
        'pc': {'shd': pc_shd} if pc_shd is not None else None,
        'hillclimb': {'shd': hc_shd} if hc_shd is not None else None,
        'random': {'shd': random_shd}
    }

def main():
    # åˆå§‹åŒ–æ¨ç†å¼•æ“
    try:
        engine = CausalReasoningEngine()
    except Exception as e:
        print(f"Failed to initialize engine: {e}")
        return

    # è¦æµ‹è¯•çš„ç½‘ç»œåˆ—è¡¨ï¼ˆæŒ‰å¤æ‚åº¦æ’åºï¼‰
    # asia: 8 nodes, 8 edges (ä¸­ç­‰å¤æ‚åº¦ï¼ŒåŒ»ç–—è¯Šæ–­)
    # sprinkler: 4 nodes, 4 edges (ç®€å•ï¼Œç»å…¸ä¾‹å­)
    # alarm: 37 nodes, 46 edges (å¤§å‹ç½‘ç»œï¼ŒåŒ»ç–—ç›‘æ§)
    # child: 20 nodes, 25 edges (ä¸­å‹ç½‘ç»œï¼Œå„¿ç§‘è¯Šæ–­)
    # sachs: 11 nodes, 17 edges (çœŸå®ç”Ÿç‰©å­¦æ•°æ®)
    networks_to_test = ['asia', 'sprinkler', 'alarm', 'child', 'sachs']
    
    all_results = []
    
    for net in networks_to_test:
        net_result = test_network(net, engine, sample_size=1000, test_all_edges=True)
        if net_result:
            all_results.append(net_result)
    
    # ============================================================
    # ç”Ÿæˆæœ€ç»ˆæ€»ç»“æŠ¥å‘Š
    # ============================================================
    print(f"\n\n{'#'*80}")
    print(f"# FINAL SUMMARY - Blind Causal Discovery Benchmark")
    print(f"{'#'*80}")
    
    # æ±‡æ€»è¡¨æ ¼
    print(f"\n{'Network':<15} {'Nodes':<8} {'Edges':<8} {'LLM-SHD':<10} {'PC-SHD':<10} {'HC-SHD':<10} {'Random':<10} {'Acc':<10}")
    print(f"{'-'*95}")
    
    for result in all_results:
        net_name = result['network']
        n_nodes = result['n_nodes']
        n_edges = result['n_edges']
        llm_shd = result['llm']['shd']
        llm_acc = result['llm']['accuracy']
        
        pc_shd = result['pc']['shd'] if result['pc'] else 'N/A'
        hc_shd = result['hillclimb']['shd'] if result['hillclimb'] else 'N/A'
        random_shd = result['random']['shd']
        
        print(f"{net_name:<15} {n_nodes:<8} {n_edges:<8} {llm_shd:<10} {pc_shd!s:<10} {hc_shd!s:<10} {random_shd:<10} {llm_acc:.1%}")
    
    print(f"{'-'*95}")
    
    # è¯¦ç»†ç»“æœ
    print(f"\n{'='*80}")
    print(f"DETAILED RESULTS")
    print(f"{'='*80}")
    
    for result in all_results:
        net_name = result['network']
        llm_shd = result['llm']['shd']
        llm_acc = result['llm']['accuracy']
        
        pc_shd = result['pc']['shd'] if result['pc'] else 'N/A'
        hc_shd = result['hillclimb']['shd'] if result['hillclimb'] else 'N/A'
        random_shd = result['random']['shd']
        
        print(f"\n## {net_name.upper()} Network")
        print(f"   LLM (Blind):  SHD={llm_shd}, Acc={llm_acc:.1%}")
        print(f"   PC:           SHD={pc_shd}")
        print(f"   HillClimb:    SHD={hc_shd}")
        print(f"   Random:       SHD={random_shd}")
        
        if pc_shd != 'N/A':
            improvement = pc_shd - llm_shd
            print(f"   ğŸ’¡ LLM vs PC: {improvement:+d} ({'Better' if improvement > 0 else 'Worse'})")
    
    print(f"\n{'='*80}")
    print(f"ğŸ“ KEY INSIGHTS:")
    print(f"   - SHD (Structural Hamming Distance): Lower is better")
    print(f"   - LLM (Blind) = Our method WITHOUT variable name information")
    print(f"   - PC/HillClimb = Traditional statistical methods")
    print(f"   - Random = Random graph baseline")
    print(f"   - Advantage: Works in privacy-preserving scenarios (no semantics)")
    print(f"{'='*80}\n")
            
    # ä¿å­˜æœ€ç»ˆç»“æœ
    with open(RESULTS_FILE, 'w', encoding='utf-8') as f:
        json.dump(all_results, f, indent=2, ensure_ascii=False)
        
    print(f"Results saved to: {RESULTS_FILE}")

if __name__ == "__main__":
    main()
