"""
P2 ä½ä¼˜å…ˆçº§å®éªŒè„šæœ¬
åŒ…å«ï¼š
- P2.1: E-SHD è¯„ä¼° (ä¸ DiBS+GPT å¯¹æ¯”)
- P2.2: åŸºåº§ç®—æ³•å®éªŒ (MMHC-Skeleton + ACR)
- P2.3: ä½æ ·æœ¬é‡é²æ£’æ€§æµ‹è¯• (100 æ ·æœ¬)
"""

import sys
import os
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..'))

import pandas as pd
import numpy as np
import json
from pgmpy.utils import get_example_model
from pgmpy.sampling import BayesianModelSampling
from utils_set.causal_reasoning_engine import CausalReasoningEngine
from utils_set.utils import path_config

# ä¼ ç»Ÿå› æœå‘ç°ç®—æ³•
try:
    from pgmpy.estimators import PC, HillClimbSearch, BicScore, MmhcEstimator
    PGMPY_AVAILABLE = True
except ImportError:
    PGMPY_AVAILABLE = False
    print("Warning: pgmpy estimators not available.")

# FCI ç®—æ³•æ”¯æŒ (causal-learn)
try:
    from causallearn.search.ConstraintBased.FCI import fci
    from causallearn.utils.cit import fisherz, chisq, gsq, mv_fisherz, kci
    CAUSALLEARN_AVAILABLE = True
except ImportError:
    CAUSALLEARN_AVAILABLE = False
    print("Warning: causal-learn not available. FCI algorithm will use fallback implementation.")

RESULTS_DIR = str(path_config.results_dir)


def compute_shd(true_edges, pred_edges):
    """è®¡ç®— SHD (ç»“æ„æ±‰æ˜è·ç¦»)"""
    true_set = set(true_edges)
    pred_set = set(pred_edges)
    
    # ç¼ºå¤±è¾¹
    missing = len(true_set - pred_set)
    # å¤šä½™è¾¹
    extra = len(pred_set - true_set)
    
    # æ–¹å‘é”™è¯¯ï¼š(A,B) in true but (B,A) in pred
    reversed_count = 0
    for (a, b) in true_set:
        if (b, a) in pred_set and (a, b) not in pred_set:
            reversed_count += 1
    
    # SHD = missing + extra (reversed å·²ç»åœ¨ missing å’Œ extra ä¸­è®¡ç®—äº†)
    return missing + extra


def compute_expected_shd(true_edges, pred_edges_list):
    """
    è®¡ç®— E-SHD (Expected SHD)
    ç”¨äºä¸è´å¶æ–¯æ–¹æ³• (DiBS+GPT) å¯¹æ¯”
    
    å¯¹äºç¡®å®šæ€§æ–¹æ³•ï¼ŒE-SHD = SHD
    å¯¹äºæ¦‚ç‡æ–¹æ³•ï¼ŒE-SHD = æœŸæœ› SHD
    """
    if not pred_edges_list:
        return None
    
    # å¯¹äºæˆ‘ä»¬çš„ç¡®å®šæ€§æ–¹æ³•ï¼Œåªæœ‰ä¸€ä¸ªé¢„æµ‹
    if isinstance(pred_edges_list[0], tuple):
        return compute_shd(true_edges, pred_edges_list)
    
    # å¯¹äºå¤šæ¬¡é‡‡æ ·çš„æƒ…å†µï¼Œè®¡ç®—å¹³å‡ SHD
    shds = [compute_shd(true_edges, pred) for pred in pred_edges_list]
    return np.mean(shds), np.std(shds)


def run_pc_algorithm(df, alpha=0.05):
    """è¿è¡Œ PC ç®—æ³•"""
    if not PGMPY_AVAILABLE:
        return None
    try:
        pc = PC(data=df)
        model = pc.estimate(significance_level=alpha)
        return list(model.edges())
    except Exception as e:
        print(f"PC algorithm failed: {e}")
        return None


def run_hillclimb_algorithm(df):
    """è¿è¡Œ HillClimb ç®—æ³•"""
    if not PGMPY_AVAILABLE:
        return None
    try:
        hc = HillClimbSearch(data=df)
        model = hc.estimate(scoring_method=BicScore(data=df))
        return list(model.edges())
    except Exception as e:
        print(f"HillClimb algorithm failed: {e}")
        return None


def run_mmhc_algorithm(df):
    """è¿è¡Œ MMHC ç®—æ³• (Max-Min Hill-Climbing)"""
    if not PGMPY_AVAILABLE:
        return None
    try:
        mmhc = MmhcEstimator(data=df)
        model = mmhc.estimate()
        return list(model.edges())
    except Exception as e:
        print(f"MMHC algorithm failed: {e}")
        return None


def get_mmhc_skeleton(df):
    """è·å– MMHC çš„éª¨æ¶ (æ— å‘è¾¹)"""
    if not PGMPY_AVAILABLE:
        return None
    try:
        mmhc = MmhcEstimator(data=df)
        skeleton = mmhc.mmpc()  # è¿”å›éª¨æ¶
        return skeleton
    except Exception as e:
        print(f"MMHC skeleton failed: {e}")
        return None


def run_dual_pc_algorithm(df, alpha=0.05):
    """
    è¿è¡Œ Dual PC ç®—æ³•
    Dual PC æ˜¯ PC ç®—æ³•çš„å˜ä½“ï¼Œé€‚ç”¨äºé«˜æ–¯è¿ç»­æ•°æ®
    ä½¿ç”¨ Fisher-Z æ£€éªŒè¿›è¡Œæ¡ä»¶ç‹¬ç«‹æ€§æµ‹è¯•
    
    Args:
        df: æ•°æ®æ¡†
        alpha: æ˜¾è‘—æ€§æ°´å¹³
    
    Returns:
        edges: æœ‰å‘è¾¹åˆ—è¡¨
        pdag_info: PDAG ä¿¡æ¯ï¼ˆåŒ…å«æ— å‘è¾¹ï¼‰
    """
    if not PGMPY_AVAILABLE:
        return None, None
    try:
        # Dual PC ä½¿ç”¨æ›´ä¸¥æ ¼çš„æ˜¾è‘—æ€§æ°´å¹³å’Œ Fisher-Z æ£€éªŒ
        # é€‚ç”¨äºè¿ç»­é«˜æ–¯æ•°æ®
        pc = PC(data=df)
        
        # å°è¯•è·å– PDAG ä»¥ä¿ç•™æ— å‘è¾¹ä¿¡æ¯
        try:
            model = pc.estimate(
                significance_level=alpha,
                return_type='pdag'
            )
            edges = list(model.edges())
            
            # æå–æ— å‘è¾¹ï¼ˆåŒå‘è¾¹ï¼‰
            undirected_edges = []
            directed_edges = []
            edge_set = set(edges)
            processed = set()
            
            for u, v in edges:
                pair = tuple(sorted((u, v)))
                if pair in processed:
                    continue
                processed.add(pair)
                
                # æ£€æŸ¥æ˜¯å¦åŒå‘ï¼ˆæ— å‘ï¼‰
                if (v, u) in edge_set:
                    undirected_edges.append((u, v))
                else:
                    directed_edges.append((u, v))
            
            pdag_info = {
                'directed_edges': directed_edges,
                'undirected_edges': undirected_edges,
                'all_edges': edges
            }
            
            return edges, pdag_info
            
        except Exception:
            # å›é€€åˆ° DAG æ¨¡å¼
            model = pc.estimate(significance_level=alpha, return_type='dag')
            edges = list(model.edges())
            return edges, {'directed_edges': edges, 'undirected_edges': [], 'all_edges': edges}
            
    except Exception as e:
        print(f"Dual PC algorithm failed: {e}")
        return None, None


def run_fci_algorithm(df, alpha=0.05):
    """
    è¿è¡Œ FCI (Fast Causal Inference) ç®—æ³•
    FCI å¯ä»¥å¤„ç†å­˜åœ¨æ½œåœ¨æ··æ·†å› å­çš„æƒ…å†µï¼Œè¾“å‡º PAG (Partial Ancestral Graph)
    
    Args:
        df: æ•°æ®æ¡†
        alpha: æ˜¾è‘—æ€§æ°´å¹³
    
    Returns:
        edges: è¾¹åˆ—è¡¨
        pag_info: PAG ä¿¡æ¯ï¼ˆåŒ…å«è¾¹ç±»å‹ï¼‰
    """
    if CAUSALLEARN_AVAILABLE:
        try:
            # ä½¿ç”¨ causal-learn çš„ FCI å®ç°
            node_names = list(df.columns)
            
            # æ£€æŸ¥æ•°æ®ç±»å‹å¹¶è½¬æ¢
            # å¯¹äºç¦»æ•£æ•°æ®ï¼Œéœ€è¦è½¬æ¢ä¸ºæ•°å€¼ç±»å‹
            df_numeric = df.copy()
            is_discrete = False
            for col in df_numeric.columns:
                if df_numeric[col].dtype == 'object' or df_numeric[col].dtype.name == 'category':
                    # å°†åˆ†ç±»æ•°æ®è½¬æ¢ä¸ºæ•°å€¼
                    df_numeric[col] = pd.Categorical(df_numeric[col]).codes
                    is_discrete = True
                elif df_numeric[col].dtype.kind in 'iub':
                    is_discrete = True
            
            data = df_numeric.values.astype(float)
            
            # é€‰æ‹©åˆé€‚çš„æ¡ä»¶ç‹¬ç«‹æ€§æ£€éªŒ
            # å¯¹äºç¦»æ•£æ•°æ®ä½¿ç”¨å¡æ–¹æ£€éªŒï¼Œè¿ç»­æ•°æ®ä½¿ç”¨ Fisher-Z
            if is_discrete:
                # ç¦»æ•£æ•°æ®ä½¿ç”¨å¡æ–¹æ£€éªŒ
                cit = chisq
            else:
                # è¿ç»­æ•°æ®ä½¿ç”¨ Fisher-Z
                cit = fisherz
            
            # è¿è¡Œ FCI
            g, edges_info = fci(data, cit, alpha)
            
            # è§£æ PAG ç»“æœ
            # PAG è¾¹ç±»å‹: -1 = circle, 1 = arrowhead, 2 = tail
            directed_edges = []
            bidirected_edges = []
            undirected_edges = []
            orientable_edges = []  # å¯ä»¥è¢«å®šå‘çš„è¾¹
            
            n = len(node_names)
            adj_matrix = g.graph
            
            for i in range(n):
                for j in range(i + 1, n):
                    if adj_matrix[i, j] != 0 or adj_matrix[j, i] != 0:
                        u, v = node_names[i], node_names[j]
                        
                        # è§£æè¾¹ç±»å‹
                        # adj_matrix[i,j] è¡¨ç¤º j ç«¯çš„æ ‡è®°
                        # adj_matrix[j,i] è¡¨ç¤º i ç«¯çš„æ ‡è®°
                        mark_at_j = adj_matrix[i, j]
                        mark_at_i = adj_matrix[j, i]
                        
                        if mark_at_j == 1 and mark_at_i == 2:
                            # i -> j (tail at i, arrow at j)
                            directed_edges.append((u, v))
                        elif mark_at_j == 2 and mark_at_i == 1:
                            # j -> i
                            directed_edges.append((v, u))
                        elif mark_at_j == 1 and mark_at_i == 1:
                            # i <-> j (bidirected)
                            bidirected_edges.append((u, v))
                        elif mark_at_j == -1 or mark_at_i == -1:
                            # åŒ…å« circle ç«¯ç‚¹ï¼Œå¯å®šå‘
                            orientable_edges.append((u, v))
                        else:
                            # æ— å‘è¾¹
                            undirected_edges.append((u, v))
            
            # åˆå¹¶æ‰€æœ‰è¾¹ç”¨äº SHD è®¡ç®—
            all_edges = directed_edges.copy()
            # å¯¹äºå¯å®šå‘è¾¹ï¼Œæš‚æ—¶æŒ‰å­—æ¯é¡ºåºå®šå‘
            for u, v in orientable_edges:
                if u < v:
                    all_edges.append((u, v))
                else:
                    all_edges.append((v, u))
            
            pag_info = {
                'directed_edges': directed_edges,
                'bidirected_edges': bidirected_edges,
                'undirected_edges': undirected_edges,
                'orientable_edges': orientable_edges,
                'all_edges': all_edges
            }
            
            return all_edges, pag_info
            
        except Exception as e:
            print(f"FCI algorithm (causal-learn) failed: {e}")
            return None, None
    else:
        # Fallback: ä½¿ç”¨ PC ç®—æ³•æ¨¡æ‹Ÿ FCI è¡Œä¸º
        # æ³¨æ„ï¼šè¿™ä¸æ˜¯çœŸæ­£çš„ FCIï¼Œä»…ç”¨äºæµ‹è¯•æ¡†æ¶
        print("Warning: Using PC as FCI fallback (causal-learn not installed)")
        if not PGMPY_AVAILABLE:
            return None, None
        try:
            pc = PC(data=df)
            try:
                model = pc.estimate(significance_level=alpha, return_type='pdag')
            except:
                model = pc.estimate(significance_level=alpha, return_type='dag')
            
            edges = list(model.edges())
            
            # æ¨¡æ‹Ÿ PAG è¾“å‡ºæ ¼å¼
            # å°†æ— å‘è¾¹æ ‡è®°ä¸ºå¯å®šå‘è¾¹
            edge_set = set(edges)
            directed_edges = []
            orientable_edges = []
            processed = set()
            
            for u, v in edges:
                pair = tuple(sorted((u, v)))
                if pair in processed:
                    continue
                processed.add(pair)
                
                if (v, u) in edge_set:
                    # åŒå‘ = å¯å®šå‘
                    orientable_edges.append((u, v))
                else:
                    directed_edges.append((u, v))
            
            # ä¸ºå¯å®šå‘è¾¹é€‰æ‹©æ–¹å‘
            all_edges = directed_edges.copy()
            for u, v in orientable_edges:
                all_edges.append((u, v))
            
            pag_info = {
                'directed_edges': directed_edges,
                'bidirected_edges': [],
                'undirected_edges': [],
                'orientable_edges': orientable_edges,
                'all_edges': all_edges,
                'is_fallback': True
            }
            
            return all_edges, pag_info
            
        except Exception as e:
            print(f"FCI fallback (PC) failed: {e}")
            return None, None


def extract_undirected_edges_from_pdag(pdag_info):
    """ä» PDAG ä¿¡æ¯ä¸­æå–æ— å‘è¾¹"""
    if pdag_info is None:
        return []
    return pdag_info.get('undirected_edges', [])


def extract_orientable_edges_from_pag(pag_info):
    """ä» PAG ä¿¡æ¯ä¸­æå–å¯å®šå‘è¾¹"""
    if pag_info is None:
        return []
    return pag_info.get('orientable_edges', [])


class P2Experimenter:
    """P2 å®éªŒæ‰§è¡Œå™¨"""
    
    def __init__(self):
        try:
            self.engine = CausalReasoningEngine()
            print(f"âœ… Causal Engine Initialized")
        except Exception as e:
            print(f"âŒ Failed to initialize engine: {e}")
            self.engine = None
    
    def run_acr_on_edges(self, df, edges, true_edges):
        """
        å¯¹ç»™å®šçš„è¾¹åˆ—è¡¨è¿è¡Œ ACR å®šå‘
        è¿”å›é¢„æµ‹çš„æœ‰å‘è¾¹å’Œå‡†ç¡®ç‡
        """
        pred_edges = []
        correct = 0
        total = 0
        details = []
        
        for source, target in edges:
            X = df[source].values
            Y = df[target].values
            
            try:
                analysis = self.engine.analyze_pair(X, Y)
                result = self.engine.infer_causality(analysis['narrative'])
                
                prediction = (
                    result.get('direction') or 
                    result.get('causal_direction') or 
                    result.get('causal_direction_judgment') or
                    'Unclear'
                )
                
                # åˆ¤æ–­æ­£ç¡®æ–¹å‘
                true_direction = None
                if (source, target) in true_edges:
                    true_direction = "A->B"
                elif (target, source) in true_edges:
                    true_direction = "B->A"
                
                if prediction == "A->B":
                    pred_edges.append((source, target))
                    is_correct = (true_direction == "A->B")
                elif prediction == "B->A":
                    pred_edges.append((target, source))
                    is_correct = (true_direction == "B->A")
                else:
                    # Unclear: éšæœºé€‰æ‹©æˆ–ä¿æŒåŸæ–¹å‘
                    pred_edges.append((source, target))
                    is_correct = (true_direction == "A->B")
                
                if true_direction:
                    total += 1
                    if is_correct:
                        correct += 1
                
                details.append({
                    'edge': f"{source}-{target}",
                    'prediction': prediction,
                    'true_direction': true_direction,
                    'is_correct': is_correct
                })
                
                status = "âœ…" if is_correct else "âŒ"
                print(f"  {status} {source}-{target}: pred={prediction}, true={true_direction}")
                
            except Exception as e:
                print(f"  âš ï¸  Error on {source}-{target}: {e}")
                pred_edges.append((source, target))
        
        accuracy = correct / total if total > 0 else 0
        return pred_edges, accuracy, details
    
    def experiment_p2_1_eshd(self, network_name="sachs", sample_size=1000):
        """
        P2.1: E-SHD è¯„ä¼°
        ä¸ DiBS+GPT (E-SHD=21.7) å¯¹æ¯”
        """
        print(f"\n{'='*60}")
        print(f"P2.1: E-SHD Evaluation on {network_name}")
        print(f"{'='*60}")
        
        # åŠ è½½ç½‘ç»œ
        model = get_example_model(network_name)
        sampler = BayesianModelSampling(model)
        df = sampler.forward_sample(size=sample_size)
        
        true_edges = list(model.edges())
        n_edges = len(true_edges)
        
        print(f"Network: {network_name}, Edges: {n_edges}")
        print(f"Baseline: DiBS+GPT E-SHD = 21.7 Â± 0.5 (from Bazaluk et al., 2025)")
        
        # è¿è¡Œ ACR-Hybrid
        print(f"\nRunning ACR-Hybrid...")
        pred_edges, accuracy, details = self.run_acr_on_edges(df, true_edges, set(true_edges))
        
        shd = compute_shd(true_edges, pred_edges)
        e_shd = shd  # ç¡®å®šæ€§æ–¹æ³•ï¼ŒE-SHD = SHD
        
        print(f"\nğŸ“Š Results:")
        print(f"  ACR-Hybrid SHD: {shd}")
        print(f"  ACR-Hybrid E-SHD: {e_shd}")
        print(f"  DiBS+GPT E-SHD: 21.7 Â± 0.5")
        print(f"  Improvement: {(21.7 - e_shd) / 21.7 * 100:.1f}%")
        
        result = {
            'experiment': 'P2.1_ESHD',
            'network': network_name,
            'sample_size': sample_size,
            'acr_shd': shd,
            'acr_eshd': e_shd,
            'acr_accuracy': accuracy,
            'dibs_gpt_eshd': 21.7,
            'improvement_pct': (21.7 - e_shd) / 21.7 * 100,
            'details': details
        }
        
        return result
    
    def experiment_p2_2_mmhc_acr(self, network_name="alarm", sample_size=1000):
        """
        P2.2: MMHC-Skeleton + ACR
        å¯¹æ¯”éª¨æ¶è´¨é‡å¯¹ ACR çš„å½±å“
        """
        print(f"\n{'='*60}")
        print(f"P2.2: MMHC-Skeleton + ACR on {network_name}")
        print(f"{'='*60}")
        
        # åŠ è½½ç½‘ç»œ
        model = get_example_model(network_name)
        sampler = BayesianModelSampling(model)
        df = sampler.forward_sample(size=sample_size)
        
        true_edges = list(model.edges())
        true_edges_set = set(true_edges)
        n_edges = len(true_edges)
        
        print(f"Network: {network_name}, Edges: {n_edges}")
        
        # 1. è¿è¡Œ MMHC è·å–å®Œæ•´ DAG
        print(f"\n[1/3] Running MMHC Algorithm...")
        mmhc_edges = run_mmhc_algorithm(df)
        if mmhc_edges:
            mmhc_shd = compute_shd(true_edges, mmhc_edges)
            print(f"  MMHC SHD: {mmhc_shd}")
        else:
            print(f"  MMHC failed, skipping...")
            mmhc_shd = None
        
        # 2. è¿è¡Œ PC è·å–éª¨æ¶
        print(f"\n[2/3] Running PC Algorithm...")
        pc_edges = run_pc_algorithm(df)
        if pc_edges:
            pc_shd = compute_shd(true_edges, pc_edges)
            print(f"  PC SHD: {pc_shd}")
        else:
            pc_shd = None
        
        # 3. MMHC-Skeleton + ACR
        print(f"\n[3/3] Running MMHC-Skeleton + ACR...")
        if mmhc_edges:
            # ä» MMHC è¾¹æå–éª¨æ¶ï¼ˆæ— å‘è¾¹å¯¹ï¼‰
            skeleton_pairs = set()
            for u, v in mmhc_edges:
                skeleton_pairs.add(tuple(sorted((u, v))))
            
            # å°†éª¨æ¶è½¬æ¢ä¸ºè¾¹åˆ—è¡¨ï¼ˆä»»æ„æ–¹å‘ï¼‰
            skeleton_edges = [(u, v) for u, v in skeleton_pairs]
            
            print(f"  MMHC Skeleton: {len(skeleton_edges)} edges")
            
            # å¯¹éª¨æ¶è¾¹è¿è¡Œ ACR
            mmhc_acr_edges, mmhc_acr_acc, mmhc_acr_details = self.run_acr_on_edges(
                df, skeleton_edges, true_edges_set
            )
            mmhc_acr_shd = compute_shd(true_edges, mmhc_acr_edges)
            
            print(f"\nğŸ“Š Results:")
            print(f"  MMHC SHD: {mmhc_shd}")
            print(f"  MMHC-Skeleton + ACR SHD: {mmhc_acr_shd}")
            print(f"  PC SHD: {pc_shd}")
            if mmhc_shd and mmhc_acr_shd < mmhc_shd:
                print(f"  ACR Improvement over MMHC: {(mmhc_shd - mmhc_acr_shd) / mmhc_shd * 100:.1f}%")
        else:
            mmhc_acr_shd = None
            mmhc_acr_acc = None
            mmhc_acr_details = []
        
        result = {
            'experiment': 'P2.2_MMHC_ACR',
            'network': network_name,
            'sample_size': sample_size,
            'mmhc_shd': mmhc_shd,
            'mmhc_acr_shd': mmhc_acr_shd,
            'mmhc_acr_accuracy': mmhc_acr_acc,
            'pc_shd': pc_shd,
            'details': mmhc_acr_details
        }
        
        return result
    
    def experiment_dual_pc_acr(self, network_name="sachs", sample_size=1000):
        """
        Dual PC + ACR å®éªŒ
        éªŒè¯ ACR å¯¹é«˜æ–¯è¿ç»­æ•°æ®ï¼ˆå¦‚ Sachsï¼‰çš„ä¼˜åŒ–èƒ½åŠ›
        Requirements: 2.1, 2.3, 2.5
        """
        print(f"\n{'='*60}")
        print(f"Dual PC + ACR Experiment on {network_name}")
        print(f"{'='*60}")
        
        # åŠ è½½ç½‘ç»œ
        model = get_example_model(network_name)
        sampler = BayesianModelSampling(model)
        df = sampler.forward_sample(size=sample_size)
        
        true_edges = list(model.edges())
        true_edges_set = set(true_edges)
        n_edges = len(true_edges)
        
        print(f"Network: {network_name}, Edges: {n_edges}")
        
        # 1. è¿è¡Œ Dual PC ç®—æ³•
        print(f"\n[1/3] Running Dual PC Algorithm...")
        dual_pc_edges, pdag_info = run_dual_pc_algorithm(df)
        
        if dual_pc_edges is None:
            print("  Dual PC failed, skipping...")
            return None
        
        dual_pc_shd = compute_shd(true_edges, dual_pc_edges)
        print(f"  Dual PC SHD: {dual_pc_shd}")
        
        # 2. æå–æ— å‘è¾¹
        undirected_edges = extract_undirected_edges_from_pdag(pdag_info)
        print(f"\n[2/3] Extracted {len(undirected_edges)} undirected edges from PDAG")
        
        # 3. å¯¹æ— å‘è¾¹è¿è¡Œ ACR
        print(f"\n[3/3] Running ACR on undirected edges...")
        
        if len(undirected_edges) > 0:
            acr_oriented_edges, acr_accuracy, acr_details = self.run_acr_on_edges(
                df, undirected_edges, true_edges_set
            )
            
            # åˆå¹¶æœ‰å‘è¾¹å’Œ ACR å®šå‘çš„è¾¹
            final_edges = pdag_info.get('directed_edges', []).copy()
            final_edges.extend(acr_oriented_edges)
            
            dual_pc_acr_shd = compute_shd(true_edges, final_edges)
        else:
            print("  No undirected edges to orient, using Dual PC result directly")
            final_edges = dual_pc_edges
            dual_pc_acr_shd = dual_pc_shd
            acr_accuracy = None
            acr_details = []
        
        # 4. è®¡ç®— F1 æŒ‡æ ‡
        true_set = set(true_edges)
        pred_set = set(final_edges)
        tp = len(true_set & pred_set)
        fp = len(pred_set - true_set)
        fn = len(true_set - pred_set)
        
        precision = tp / (tp + fp) if (tp + fp) > 0 else 0
        recall = tp / (tp + fn) if (tp + fn) > 0 else 0
        f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0
        
        print(f"\nğŸ“Š Results:")
        print(f"  Dual PC SHD: {dual_pc_shd}")
        print(f"  Dual PC + ACR SHD: {dual_pc_acr_shd}")
        print(f"  Improvement: {dual_pc_shd - dual_pc_acr_shd}")
        print(f"  F1: {f1:.3f}")
        
        result = {
            'experiment': 'Dual_PC_ACR',
            'network': network_name,
            'sample_size': sample_size,
            'dual_pc_shd': dual_pc_shd,
            'dual_pc_acr_shd': dual_pc_acr_shd,
            'shd_improvement': dual_pc_shd - dual_pc_acr_shd,
            'f1': f1,
            'precision': precision,
            'recall': recall,
            'undirected_edges_count': len(undirected_edges),
            'acr_accuracy': acr_accuracy,
            'details': acr_details
        }
        
        return result
    
    def experiment_fci_acr(self, network_name="asia", sample_size=1000):
        """
        FCI + ACR å®éªŒ
        éªŒè¯ ACR å®šå‘èƒ½åŠ›åœ¨å¤„ç†æ½œåœ¨æ··æ·†å› å­çš„ PAGs ä¸Šçš„æ•ˆæœ
        Requirements: 2.3, 2.4, 2.6
        """
        print(f"\n{'='*60}")
        print(f"FCI + ACR Experiment on {network_name}")
        print(f"{'='*60}")
        
        # åŠ è½½ç½‘ç»œ
        model = get_example_model(network_name)
        sampler = BayesianModelSampling(model)
        df = sampler.forward_sample(size=sample_size)
        
        true_edges = list(model.edges())
        true_edges_set = set(true_edges)
        n_edges = len(true_edges)
        
        print(f"Network: {network_name}, Edges: {n_edges}")
        
        # 1. è¿è¡Œ FCI ç®—æ³•
        print(f"\n[1/3] Running FCI Algorithm...")
        fci_edges, pag_info = run_fci_algorithm(df)
        
        if fci_edges is None:
            print("  FCI failed, skipping...")
            return None
        
        fci_shd = compute_shd(true_edges, fci_edges)
        print(f"  FCI SHD: {fci_shd}")
        
        if pag_info and pag_info.get('is_fallback'):
            print("  (Note: Using PC as FCI fallback)")
        
        # 2. æå–å¯å®šå‘è¾¹
        orientable_edges = extract_orientable_edges_from_pag(pag_info)
        print(f"\n[2/3] Extracted {len(orientable_edges)} orientable edges from PAG")
        
        # 3. å¯¹å¯å®šå‘è¾¹è¿è¡Œ ACR
        print(f"\n[3/3] Running ACR on orientable edges...")
        
        if len(orientable_edges) > 0:
            acr_oriented_edges, acr_accuracy, acr_details = self.run_acr_on_edges(
                df, orientable_edges, true_edges_set
            )
            
            # åˆå¹¶å·²å®šå‘è¾¹å’Œ ACR å®šå‘çš„è¾¹
            final_edges = pag_info.get('directed_edges', []).copy()
            final_edges.extend(acr_oriented_edges)
            
            fci_acr_shd = compute_shd(true_edges, final_edges)
        else:
            print("  No orientable edges, using FCI result directly")
            final_edges = fci_edges
            fci_acr_shd = fci_shd
            acr_accuracy = None
            acr_details = []
        
        # 4. è®¡ç®— F1 æŒ‡æ ‡
        true_set = set(true_edges)
        pred_set = set(final_edges)
        tp = len(true_set & pred_set)
        fp = len(pred_set - true_set)
        fn = len(true_set - pred_set)
        
        precision = tp / (tp + fp) if (tp + fp) > 0 else 0
        recall = tp / (tp + fn) if (tp + fn) > 0 else 0
        f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0
        
        print(f"\nğŸ“Š Results:")
        print(f"  FCI SHD: {fci_shd}")
        print(f"  FCI + ACR SHD: {fci_acr_shd}")
        print(f"  Improvement: {fci_shd - fci_acr_shd}")
        print(f"  F1: {f1:.3f}")
        
        result = {
            'experiment': 'FCI_ACR',
            'network': network_name,
            'sample_size': sample_size,
            'fci_shd': fci_shd,
            'fci_acr_shd': fci_acr_shd,
            'shd_improvement': fci_shd - fci_acr_shd,
            'f1': f1,
            'precision': precision,
            'recall': recall,
            'orientable_edges_count': len(orientable_edges),
            'acr_accuracy': acr_accuracy,
            'is_fallback': pag_info.get('is_fallback', False) if pag_info else False,
            'details': acr_details
        }
        
        return result

    def experiment_p2_3_low_sample(self, network_name="asia", sample_sizes=[100, 500, 1000]):
        """
        P2.3: ä½æ ·æœ¬é‡é²æ£’æ€§æµ‹è¯•
        åœ¨ä¸åŒæ ·æœ¬é‡ä¸‹å¯¹æ¯” ACR-Hybrid vs PC/HillClimb
        """
        print(f"\n{'='*60}")
        print(f"P2.3: Low Sample Robustness Test on {network_name}")
        print(f"{'='*60}")
        
        # åŠ è½½ç½‘ç»œ
        model = get_example_model(network_name)
        true_edges = list(model.edges())
        true_edges_set = set(true_edges)
        n_edges = len(true_edges)
        
        print(f"Network: {network_name}, Edges: {n_edges}")
        print(f"Sample sizes to test: {sample_sizes}")
        
        results_by_sample = []
        
        for sample_size in sample_sizes:
            print(f"\n--- Sample Size: {sample_size} ---")
            
            sampler = BayesianModelSampling(model)
            df = sampler.forward_sample(size=sample_size)
            
            # PC
            pc_edges = run_pc_algorithm(df)
            pc_shd = compute_shd(true_edges, pc_edges) if pc_edges else None
            print(f"  PC SHD: {pc_shd}")
            
            # HillClimb
            hc_edges = run_hillclimb_algorithm(df)
            hc_shd = compute_shd(true_edges, hc_edges) if hc_edges else None
            print(f"  HillClimb SHD: {hc_shd}")
            
            # ACR-Hybrid (å¯¹çœŸå®è¾¹è¿è¡Œ)
            print(f"  Running ACR-Hybrid...")
            acr_edges, acr_acc, acr_details = self.run_acr_on_edges(
                df, true_edges, true_edges_set
            )
            acr_shd = compute_shd(true_edges, acr_edges)
            print(f"  ACR-Hybrid SHD: {acr_shd}, Accuracy: {acr_acc:.1%}")
            
            results_by_sample.append({
                'sample_size': sample_size,
                'pc_shd': pc_shd,
                'hillclimb_shd': hc_shd,
                'acr_shd': acr_shd,
                'acr_accuracy': acr_acc
            })
        
        print(f"\nğŸ“Š Summary Table:")
        print(f"{'Sample':<10} {'PC':<8} {'HillClimb':<12} {'ACR-Hybrid':<12}")
        print(f"{'-'*42}")
        for r in results_by_sample:
            print(f"{r['sample_size']:<10} {r['pc_shd'] or 'N/A':<8} {r['hillclimb_shd'] or 'N/A':<12} {r['acr_shd']:<12}")
        
        result = {
            'experiment': 'P2.3_Low_Sample',
            'network': network_name,
            'results_by_sample': results_by_sample
        }
        
        return result


def main():
    import argparse
    parser = argparse.ArgumentParser(description='P2 Experiments')
    parser.add_argument('--exp', type=str, default='all',
                        choices=['all', 'p2.1', 'p2.2', 'p2.3', 'dual_pc', 'fci'],
                        help='Which experiment to run')
    parser.add_argument('--network', type=str, default=None,
                        help='Network to test (default varies by experiment)')
    parser.add_argument('--sample_size', type=int, default=1000,
                        help='Sample size for experiments')
    args = parser.parse_args()
    
    experimenter = P2Experimenter()
    if not experimenter.engine:
        print("Engine initialization failed. Exiting.")
        return
    
    all_results = {}
    
    if args.exp in ['all', 'p2.1']:
        network = args.network or 'sachs'
        result = experimenter.experiment_p2_1_eshd(network, args.sample_size)
        all_results['p2.1'] = result
    
    if args.exp in ['all', 'p2.2']:
        network = args.network or 'alarm'
        result = experimenter.experiment_p2_2_mmhc_acr(network, args.sample_size)
        all_results['p2.2'] = result
    
    if args.exp in ['all', 'p2.3']:
        network = args.network or 'asia'
        result = experimenter.experiment_p2_3_low_sample(network)
        all_results['p2.3'] = result
    
    # æ–°å¢: Dual PC + ACR å®éªŒ
    if args.exp in ['all', 'dual_pc']:
        network = args.network or 'sachs'
        result = experimenter.experiment_dual_pc_acr(network, args.sample_size)
        all_results['dual_pc_acr'] = result
    
    # æ–°å¢: FCI + ACR å®éªŒ
    if args.exp in ['all', 'fci']:
        network = args.network or 'asia'
        result = experimenter.experiment_fci_acr(network, args.sample_size)
        all_results['fci_acr'] = result
    
    # ä¿å­˜ç»“æœ
    output_file = os.path.join(RESULTS_DIR, 'p2_experiment_results.json')
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(all_results, f, indent=2, ensure_ascii=False)
    print(f"\nğŸ’¾ All results saved to: {output_file}")


if __name__ == "__main__":
    main()
