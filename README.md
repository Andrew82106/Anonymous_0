# LLM Bayesian - Abstract Causal Reasoning (ACR) Framework

åŸºäº**æŠ½è±¡å› æœæ¨ç† (Abstract Causal Reasoning, ACR)** çš„ LLM å› æœå‘ç°æ¡†æ¶

---

## ğŸ“– é¡¹ç›®ç®€ä»‹

æœ¬é¡¹ç›®å®ç°äº†ä¸€ä¸ªåˆ›æ–°çš„å› æœå‘ç°æ–¹æ³•ï¼Œé€šè¿‡å°†**ç»Ÿè®¡ç‰¹å¾ç¿»è¯‘ä¸ºè‡ªç„¶è¯­è¨€å™äº‹**ï¼Œè®©å¤§å‹è¯­è¨€æ¨¡å‹ (LLM) åœ¨**å®Œå…¨è„±æ•**çš„æ¡ä»¶ä¸‹æ¨æ–­å˜é‡ä¹‹é—´çš„å› æœå…³ç³»ã€‚

### æ ¸å¿ƒæ€æƒ³
ä¼ ç»Ÿçš„ LLM å› æœæ¨æ–­ç ”ç©¶å¸¸è¢«è´¨ç–‘åªæ˜¯"è®°ä½"äº†è®­ç»ƒæ•°æ®ä¸­çš„å…±ç°å…³ç³»ï¼ˆå¦‚"å¸çƒŸâ†’ç™Œç—‡"ï¼‰ã€‚  
æˆ‘ä»¬çš„æ–¹æ³•é€šè¿‡ï¼š
1. **åŒ¿ååŒ–å˜é‡**ï¼ˆVar_A, Var_Bï¼‰
2. **æå–ç»Ÿè®¡è¡Œä¸ºç‰¹å¾**ï¼ˆæ®‹å·®ç‹¬ç«‹æ€§ã€åˆ†å¸ƒå½¢æ€ã€æ‹Ÿåˆåº¦ï¼‰
3. **ç¿»è¯‘ä¸ºè‡ªç„¶è¯­è¨€å™äº‹**ï¼ˆå¦‚"A->B çš„è¯¯å·®å‡ ä¹æ˜¯éšæœºçš„ï¼Œä½† B->A çš„è¯¯å·®ä¸­ä»åŒ…å« B çš„ç—•è¿¹"ï¼‰

å¼ºåˆ¶ LLM ä¾é **é€»è¾‘æ¨ç†**è€Œéè¯­ä¹‰çŸ¥è¯†æ¥åˆ¤æ–­å› æœæ–¹å‘ã€‚

---

## ğŸ¯ æ ¸å¿ƒåˆ›æ–°

### 1. å¤šç»´åº¦ç»Ÿè®¡ç‰¹å¾æå–å™¨ (Multi-Dimensional Stat-to-Lang Translator)

æœ¬é¡¹ç›®ä¸ä»…ä»…æ˜¯å•ä¸€çš„ LiNGAM æˆ– ANM å®ç°ï¼Œè€Œæ˜¯ä¸€ä¸ª**è‡ªé€‚åº”çš„ç»Ÿè®¡ç‰¹å¾æå–ç³»ç»Ÿ**ï¼Œèƒ½å¤Ÿæ ¹æ®æ•°æ®ç±»å‹è‡ªåŠ¨é€‰æ‹©æœ€ä¼˜ç­–ç•¥ï¼š

| æ•°æ®ç±»å‹ | æ ¸å¿ƒç†è®º | å…³é”®æŒ‡æ ‡ | é€‚ç”¨åœºæ™¯ |
|---------|---------|---------|---------|
| **è¿ç»­å˜é‡** | LiNGAM | ååº¦ã€å³°åº¦ï¼ˆéé«˜æ–¯æ€§ï¼‰ | çº¿æ€§å› æœå…³ç³» |
| | Non-linear ANM | äº’ä¿¡æ¯ (MI)ã€å¤šé¡¹å¼æ‹Ÿåˆ RÂ² | éçº¿æ€§å› æœå…³ç³» |
| | ç¨³å®šæ€§åˆ†æ | å¼‚æ–¹å·®æ€§æ£€æµ‹ | æ•æ‰åå‘æ‹Ÿåˆçš„ä¸ç¨³å®šæ€§ |
| **ç¦»æ•£å˜é‡** | ä¿¡æ¯è®º | æ¡ä»¶ç†µã€è¾¹é™…ç†µ | çœŸå®ä¸–ç•Œç¦»æ•£æ•°æ®ï¼ˆbnlearnï¼‰ |
| | é¢„æµ‹èƒ½åŠ› | é€»è¾‘å›å½’å‡†ç¡®ç‡ | åˆ†ç±»å˜é‡çš„å› æœåˆ¤æ–­ |

**å…³é”®çªç ´**ï¼šå°†æ•°å€¼ç»Ÿè®¡ç‰¹å¾ï¼ˆå¦‚ MI=0.35, H(Y|X)=0.72ï¼‰è½¬åŒ–ä¸ºè‡ªç„¶è¯­è¨€å™äº‹ï¼Œä½¿ LLM èƒ½å¤Ÿåƒäººç±»ä¸“å®¶ä¸€æ ·è¿›è¡Œå› æœæ¨ç†ã€‚

### 2. LLM ä½œä¸º"å…ƒç»Ÿè®¡å­¦å®¶" (LLM as Meta-Statistician)

LLM ä¸å†æ˜¯ç®€å•çš„åˆ†ç±»å™¨ï¼Œè€Œæ˜¯ä¸€ä¸ªèƒ½å¤Ÿï¼š
- **ç»¼åˆå¤šæºè¯æ®**ï¼šæƒè¡¡æ¥è‡ªç†µã€æ‹Ÿåˆåº¦ã€æ®‹å·®ç‹¬ç«‹æ€§ç­‰å¤šä¸ªç»´åº¦çš„è¯æ®ã€‚
- **å¤„ç†çŸ›ç›¾ä¿¡å·**ï¼šåœ¨å¤æ‚åº¦ä¸å¯¹ç§°ä¸æ®‹å·®ç‹¬ç«‹æ€§å†²çªæ—¶åšå‡ºåˆç†åˆ¤æ–­ã€‚
- **è¾“å‡ºå¯è§£é‡Šæ¨ç†é“¾**ï¼šæä¾›å®Œæ•´çš„æ¨ç†è¿‡ç¨‹ï¼Œè€Œéé»‘ç›’å†³ç­–ã€‚

---

## ğŸš€ å¿«é€Ÿå¼€å§‹

### å®‰è£…ä¾èµ–
```bash
pip install numpy scipy scikit-learn pandas pydantic openai zhipuai pyyaml
```

### é…ç½®æ¨¡å‹
ç¼–è¾‘ `llms/config.yaml`ï¼Œè®¾ç½®é»˜è®¤ä½¿ç”¨çš„æ¨¡å‹ï¼š
```yaml
used_model: "deepseek-ai/DeepSeek-V3.1"
```

### è¿è¡Œå®éªŒ
```bash
# ä½¿ç”¨é»˜è®¤é…ç½®
python3 run_experiment.py

# æŒ‡å®šå‚æ•°
python3 run_experiment.py --model "gpt-4-turbo" --samples 1000 --output results.json
```

### è¾“å‡º
- **æ§åˆ¶å°**: å®æ—¶æ˜¾ç¤ºæ¨ç†è¿›åº¦å’Œå‡†ç¡®ç‡
- **JSON æ–‡ä»¶**: `experiment_results.json` - å®Œæ•´çš„æ¨ç†ç»“æœ

---

## ğŸ“ é¡¹ç›®ç»“æ„

```
LLMBayesian/
â”œâ”€â”€ ğŸ“‚ background/                # é¡¹ç›®èƒŒæ™¯æ–‡æ¡£
â”‚   â””â”€â”€ task.md                   # å®éªŒè®¡åˆ’å’Œè¿›åº¦è¿½è¸ª
â”œâ”€â”€ ğŸ“‚ results/                   # å®éªŒç»“æœå­˜å‚¨
â”‚   â”œâ”€â”€ experiment_results.json   # åˆæˆæ•°æ®å®éªŒç»“æœ
â”‚   â””â”€â”€ real_network_results.json # çœŸå®ç½‘ç»œæµ‹è¯•ç»“æœ
â”œâ”€â”€ ğŸ“‚ tests/                     # æµ‹è¯•è„šæœ¬
â”‚   â”œâ”€â”€ run_experiment.py         # è¿è¡Œåˆæˆæ•°æ®å®éªŒ
â”‚   â””â”€â”€ test_real_networks.py     # æµ‹è¯•çœŸå®è´å¶æ–¯ç½‘ç»œ
â”œâ”€â”€ ğŸ“‚ utils_set/                 # æ ¸å¿ƒåŠŸèƒ½æ¨¡å—
â”‚   â”œâ”€â”€ stat_translator.py        # ç»Ÿè®¡ç‰¹å¾ -> è‡ªç„¶è¯­è¨€å™äº‹ï¼ˆæ”¯æŒ HSICï¼‰
â”‚   â”œâ”€â”€ data_generator.py         # åˆæˆå› æœæ•°æ®ç”Ÿæˆå™¨
â”‚   â”œâ”€â”€ causal_reasoning_engine.py # ç«¯åˆ°ç«¯æ¨ç†å¼•æ“
â”‚   â”œâ”€â”€ prompts.py                # Prompt æ¨¡æ¿åº“ï¼ˆSherlock Holmes é£æ ¼ï¼‰
â”‚   â”œâ”€â”€ causal_inference_schema.py # Pydantic å“åº”æ¨¡å‹
â”‚   â””â”€â”€ utils.py                  # é…ç½®åŠ è½½å·¥å…·
â”œâ”€â”€ ğŸ“‚ llms/                      # LLM ç®¡ç†ç³»ç»Ÿ
â”‚   â”œâ”€â”€ manager.py                # LLM ç®¡ç†å™¨
â”‚   â”œâ”€â”€ config.yaml               # æ¨¡å‹é…ç½®ï¼ˆæ”¯æŒ OpenAI/ZhipuAI/ModelScopeï¼‰
â”‚   â”œâ”€â”€ base.py                   # LLM åŸºç±»
â”‚   â””â”€â”€ providers/                # å„æä¾›å•†å®ç°
â”œâ”€â”€ README.md                     # æœ¬æ–‡ä»¶
â”œâ”€â”€ MODIFICATION_SUMMARY.md       # æœ€æ–°ä¿®æ”¹æ€»ç»“
â””â”€â”€ PROJECT_STRUCTURE.md          # è¯¦ç»†é¡¹ç›®ç»“æ„è¯´æ˜
```

ğŸ’¡ **è¯¦ç»†çš„æ–‡ä»¶ç»„ç»‡è¯´æ˜è¯·å‚è§** [`PROJECT_STRUCTURE.md`](./PROJECT_STRUCTURE.md)

---

## ğŸ§ª å®éªŒç»“æœ (æœ€æ–°)

### åˆæˆæ•°æ®é›† (Synthetic Data)
- **å‡†ç¡®ç‡**: **100% (3/3)** å› æœæ¡ˆä¾‹ ğŸ‰
- âœ… **LiNGAM** (çº¿æ€§éé«˜æ–¯): æ­£ç¡®ï¼ˆååº¦ä¿¡å·ï¼‰
- âœ… **Reverse** (åå‘å› æœ): æ­£ç¡®ï¼ˆLiNGAM åŸç†ï¼‰
- âœ… **ANM** (éçº¿æ€§): **æ­£ç¡®**ï¼ˆMLP å¼ºæ‹Ÿåˆ + HSIC å½»åº•è§£å†³æ¬ æ‹Ÿåˆé—®é¢˜ï¼‰
- âœ… **Confounder/Independent**: æ­£ç¡®è¯†åˆ«ä¸º Unclear

### çœŸå®ä¸–ç•Œæ•°æ® (Real-World Benchmarks)

#### æ‰©å±•åŸºå‡†æµ‹è¯•ç»“æœï¼ˆä¸ä¼ ç»Ÿç®—æ³•å¯¹æ¯”ï¼‰

| ç½‘ç»œ | è§„æ¨¡ | LLM-SHD | PC-SHD | HillClimb-SHD | Random-SHD | LLMå‡†ç¡®ç‡ |
|------|------|---------|---------|---------------|------------|----------|
| **Asia** | 8 nodes, 8 edges | **4** | 12 | 16 | 16 | 62.5% |
| **Sprinkler** | 4 nodes, 4 edges | 1 | **0** | **0** | 6 | 75.0% |
| **Alarm** | 37 nodes, 46 edges | â³ | â³ | â³ | â³ | â³ |
| **Child** | 20 nodes, 25 edges | â³ | â³ | â³ | â³ | â³ |
| **Sachs** | 11 nodes, 17 edges | â³ | â³ | â³ | â³ | â³ |

**SHD (Structural Hamming Distance)**: è¶Šä½è¶Šå¥½ï¼Œ0 è¡¨ç¤ºå®Œç¾å¤åŸ

**å…³é”®å‘ç°**:
- âœ… **å¤æ‚ç½‘ç»œä¼˜åŠ¿**: åœ¨ Asia ç½‘ç»œä¸Šæ˜¾è‘—ä¼˜äºä¼ ç»Ÿç®—æ³•ï¼ˆSHD=4 vs PC=12, **67%æå‡**ï¼‰
- âš ï¸ **ç®€å•ç½‘ç»œåŠ£åŠ¿**: Sprinkler ä¸Šä¼ ç»Ÿç®—æ³•è¾¾åˆ°å®Œç¾ï¼ˆSHD=0ï¼‰ï¼ŒLLM ç•¥é€Šï¼ˆSHD=1ï¼‰
- ğŸ¯ **æ ¸å¿ƒå®šä½**: **Blind Causal Discovery**ï¼ˆæ— è¯­ä¹‰ä¿¡æ¯åœºæ™¯ï¼‰ï¼Œéšç§ä¿æŠ¤é¢†åŸŸçš„é¦–ä¸ª LLM æ–¹æ³•

### å…³é”®åˆ›æ–°
1. **å®¢è§‚å™äº‹ (Objective Narrative)**: å°†åˆ¤å†³æƒäº¤ç»™ LLMï¼Œä»…æä¾›ç›¸å¯¹å·®å¼‚çš„å®¢è§‚æè¿°ï¼Œé¿å…ç¡¬ç¼–ç åè§ã€‚
2. **MLP éçº¿æ€§æ‹Ÿåˆ**: æ›¿ä»£å¤šé¡¹å¼å›å½’ï¼Œå½»åº•è§£å†³ ANM æ¡ˆä¾‹çš„æ¬ æ‹Ÿåˆé—®é¢˜ï¼ˆå‡†ç¡®ç‡ 0% â†’ 100%ï¼‰ã€‚
3. **IGCI åŸç†**: åœ¨ç¦»æ•£æ•°æ®ä¸­ï¼Œ**è¾¹ç¼˜ç†µ (Marginal Entropy)** ä¼˜äºæ¡ä»¶ç†µï¼Œä¿®æ­£"é¢„æµ‹é™·é˜±"ã€‚
4. **é‡åŒ–å¯¹æ¯”æ¡†æ¶**: å¼•å…¥ SHD æŒ‡æ ‡ï¼Œä¸ PC/HillClimb/Random ä¼ ç»Ÿç®—æ³•åŒå°ç«æŠ€ã€‚

---

## ğŸ”§ ä½¿ç”¨ç¤ºä¾‹

### 1. è¿è¡Œå®Œæ•´å®éªŒ
```bash
cd tests
python run_experiment.py --model gpt-4-turbo --samples 1000
```

### 2. æµ‹è¯•çœŸå®ç½‘ç»œ
```bash
cd tests
python test_real_networks.py
```

### 3. ä»£ç é›†æˆç¤ºä¾‹

**ç”Ÿæˆæ•°æ®**ï¼š
```python
from utils_set.data_generator import CausalDataGenerator

generator = CausalDataGenerator(random_seed=42)
datasets = generator.generate_batch(n_samples=500)
```

**åˆ†æå•ä¸ªæ•°æ®å¯¹**ï¼š
```python
from utils_set.stat_translator import StatTranslator

translator = StatTranslator()
stats = translator.analyze(X, Y)
narrative = translator.generate_narrative(stats)
print(narrative)
```

**ä½¿ç”¨ LLM æ¨ç†**ï¼š
```python
from utils_set.causal_reasoning_engine import CausalReasoningEngine

engine = CausalReasoningEngine(model_name="gpt-4-turbo")
results = engine.run_experiment(datasets, save_results=True)
```

---

## ğŸ“ˆ ä¸‹ä¸€æ­¥å·¥ä½œ

### è¿‘æœŸ (Immediate)
- [x] **MLP å‡çº§**: å¼•å…¥ç¥ç»ç½‘ç»œå›å½’è§£å†³ ANM æ¬ æ‹Ÿåˆã€‚
- [x] **Prompt ä¿®æ­£**: å¼•å…¥ IGCI åŸç†è§£å†³ç¦»æ•£æ•°æ®è¯¯åˆ¤ã€‚
- [x] **é‡åŒ–å¯¹æ¯”**: å®ç° SHD è®¡ç®—å’Œä¼ ç»Ÿç®—æ³• baselineï¼ˆPC, HillClimbï¼‰ã€‚
- [x] **æ‰©å±•æµ‹è¯•**: åœ¨ Asia, Sprinkler, Alarm, Child, Sachs ç½‘ç»œä¸Šæµ‹è¯•ï¼ˆè¿›è¡Œä¸­ï¼‰ã€‚
- [ ] **è®ºæ–‡å†™ä½œ**: æ’°å†™ Methodology å’Œ Blind Causal Discovery å®éªŒç« èŠ‚ã€‚
- [ ] **ç«å“å¯¹ç…§**: éªŒè¯ PromptBN åœ¨ Blind Setting ä¸‹çš„æ€§èƒ½å´©æºƒã€‚

### é•¿æœŸ (Long-term)
- [ ] å®ç°"å…ƒè®¤çŸ¥ä»²è£"æœºåˆ¶ï¼ˆç»¼åˆå¤šç§ç®—æ³•ï¼‰ã€‚
- [ ] åœ¨å¤§è§„æ¨¡çœŸå®æ•°æ®é›†ä¸ŠéªŒè¯ã€‚
- [ ] æŠ•ç¨¿é¡¶çº§ä¼šè®® (NeurIPS/ICML/ICLR)ã€‚

---

## ğŸ“ è®ºæ–‡è¿›åº¦

è¯¦è§ [task.md](task.md)

**å½“å‰é˜¶æ®µ**: ç¬¬ä¸‰é˜¶æ®µå·²å®Œæˆï¼Œè¿›å…¥ç¬¬å››é˜¶æ®µï¼ˆè¯„ä¼°ä¸åˆ†æï¼‰

---

## ğŸ¤ è´¡çŒ®

æ¬¢è¿æäº¤ Issue å’Œ Pull Requestï¼

---

## ğŸ“„ è®¸å¯è¯

MIT License

---

## ğŸ™ è‡´è°¢

- bnlearn: https://github.com/erdogant/bnlearn
- LiNGAM ç†è®º: Shimizu et al. (2006)
- ANM ç†è®º: Hoyer et al. (2009)
