# LLM Bayesian - Abstract Causal Reasoning (ACR) Framework

åŸºäº**æŠ½è±¡å› æœæ¨ç† (Abstract Causal Reasoning, ACR)** çš„ LLM å› æœå‘ç°æ¡†æ¶

---

## ğŸ“– é¡¹ç›®ç®€ä»‹

æœ¬é¡¹ç›®å®ç°äº†ä¸€ä¸ªåˆ›æ–°çš„å› æœå‘ç°æ–¹æ³•ï¼Œé€šè¿‡å°†**ç»Ÿè®¡ç‰¹å¾ç¿»è¯‘ä¸ºè‡ªç„¶è¯­è¨€å™äº‹**ï¼Œè®©å¤§å‹è¯­è¨€æ¨¡å‹ (LLM) åœ¨**å®Œå…¨è„±æ•**çš„æ¡ä»¶ä¸‹æ¨æ–­å˜é‡ä¹‹é—´çš„å› æœå…³ç³»ã€‚

### æ ¸å¿ƒæ€æƒ³
ä¼ ç»Ÿçš„ LLM å› æœæ¨æ–­ç ”ç©¶å¸¸è¢«è´¨ç–‘åªæ˜¯"è®°ä½"äº†è®­ç»ƒæ•°æ®ä¸­çš„å…±ç°å…³ç³»ï¼ˆå¦‚"å¸çƒŸâ†’ç™Œç—‡"ï¼‰ã€‚  
æˆ‘ä»¬çš„æ–¹æ³•é€šè¿‡ï¼š
1. **åŒ¿ååŒ–å˜é‡**ï¼ˆVar_A, Var_Bï¼‰
2. **æå–ç»Ÿè®¡è¡Œä¸ºç‰¹å¾**ï¼ˆæ®‹å·®ç‹¬ç«‹æ€§ã€åˆ†å¸ƒå½¢æ€ã€æ‹Ÿåˆåº¦ï¼‰
3. **ç¿»è¯‘ä¸ºè‡ªç„¶è¯­è¨€å™äº‹**ï¼ˆå¦‚"A->B çš„è¯¯å·®å‡ ä¹æ˜¯éšæœºçš„ï¼Œä½† B->A çš„è¯¯å·®ä¸­ä»åŒ…å« B çš„ç—•è¿¹"ï¼‰

å¼ºåˆ¶ LLM ä¾é **é€»è¾‘æ¨ç†**è€Œéè¯­ä¹‰çŸ¥è¯†æ¥åˆ¤æ–­å› æœæ–¹å‘ã€‚

---

## ğŸ¯ æ ¸å¿ƒåˆ›æ–°

### 1. å¤šç»´åº¦ç»Ÿè®¡ç‰¹å¾æå–å™¨ (Multi-Dimensional Stat-to-Lang Translator)

æœ¬é¡¹ç›®ä¸ä»…ä»…æ˜¯å•ä¸€çš„ LiNGAM æˆ– ANM å®ç°ï¼Œè€Œæ˜¯ä¸€ä¸ª**è‡ªé€‚åº”çš„ç»Ÿè®¡ç‰¹å¾æå–ç³»ç»Ÿ**ï¼Œèƒ½å¤Ÿæ ¹æ®æ•°æ®ç±»å‹è‡ªåŠ¨é€‰æ‹©æœ€ä¼˜ç­–ç•¥ï¼š

| æ•°æ®ç±»å‹ | æ ¸å¿ƒç†è®º | å…³é”®æŒ‡æ ‡ | é€‚ç”¨åœºæ™¯ |
|---------|---------|---------|---------|
| **è¿ç»­å˜é‡** | LiNGAM | ååº¦ã€å³°åº¦ï¼ˆéé«˜æ–¯æ€§ï¼‰ | çº¿æ€§å› æœå…³ç³» |
| | Non-linear ANM | äº’ä¿¡æ¯ (MI)ã€å¤šé¡¹å¼æ‹Ÿåˆ RÂ² | éçº¿æ€§å› æœå…³ç³» |
| | ç¨³å®šæ€§åˆ†æ | å¼‚æ–¹å·®æ€§æ£€æµ‹ | æ•æ‰åå‘æ‹Ÿåˆçš„ä¸ç¨³å®šæ€§ |
| **ç¦»æ•£å˜é‡** | ä¿¡æ¯è®º | æ¡ä»¶ç†µã€è¾¹é™…ç†µ | çœŸå®ä¸–ç•Œç¦»æ•£æ•°æ®ï¼ˆbnlearnï¼‰ |
| | é¢„æµ‹èƒ½åŠ› | é€»è¾‘å›å½’å‡†ç¡®ç‡ | åˆ†ç±»å˜é‡çš„å› æœåˆ¤æ–­ |

**å…³é”®çªç ´**ï¼šå°†æ•°å€¼ç»Ÿè®¡ç‰¹å¾ï¼ˆå¦‚ MI=0.35, H(Y|X)=0.72ï¼‰è½¬åŒ–ä¸ºè‡ªç„¶è¯­è¨€å™äº‹ï¼Œä½¿ LLM èƒ½å¤Ÿåƒäººç±»ä¸“å®¶ä¸€æ ·è¿›è¡Œå› æœæ¨ç†ã€‚

### 2. LLM ä½œä¸º"å…ƒç»Ÿè®¡å­¦å®¶" (LLM as Meta-Statistician)

LLM ä¸å†æ˜¯ç®€å•çš„åˆ†ç±»å™¨ï¼Œè€Œæ˜¯ä¸€ä¸ªèƒ½å¤Ÿï¼š
- **ç»¼åˆå¤šæºè¯æ®**ï¼šæƒè¡¡æ¥è‡ªç†µã€æ‹Ÿåˆåº¦ã€æ®‹å·®ç‹¬ç«‹æ€§ç­‰å¤šä¸ªç»´åº¦çš„è¯æ®ã€‚
- **å¤„ç†çŸ›ç›¾ä¿¡å·**ï¼šåœ¨å¤æ‚åº¦ä¸å¯¹ç§°ä¸æ®‹å·®ç‹¬ç«‹æ€§å†²çªæ—¶åšå‡ºåˆç†åˆ¤æ–­ã€‚
- **è¾“å‡ºå¯è§£é‡Šæ¨ç†é“¾**ï¼šæä¾›å®Œæ•´çš„æ¨ç†è¿‡ç¨‹ï¼Œè€Œéé»‘ç›’å†³ç­–ã€‚

---

## ğŸš€ å¿«é€Ÿå¼€å§‹

### å®‰è£…ä¾èµ–
```bash
pip install numpy scipy scikit-learn pandas pydantic openai zhipuai pyyaml
```

### é…ç½®æ¨¡å‹
ç¼–è¾‘ `llms/config.yaml`ï¼Œè®¾ç½®é»˜è®¤ä½¿ç”¨çš„æ¨¡å‹ï¼š
```yaml
used_model: "deepseek-ai/DeepSeek-V3.1"
```

### è¿è¡Œå®éªŒ
```bash
# ä½¿ç”¨é»˜è®¤é…ç½®
python3 run_experiment.py

# æŒ‡å®šå‚æ•°
python3 run_experiment.py --model "gpt-4-turbo" --samples 1000 --output results.json
```

### è¾“å‡º
- **æ§åˆ¶å°**: å®æ—¶æ˜¾ç¤ºæ¨ç†è¿›åº¦å’Œå‡†ç¡®ç‡
- **JSON æ–‡ä»¶**: `experiment_results.json` - å®Œæ•´çš„æ¨ç†ç»“æœ

---

## ğŸ“ é¡¹ç›®ç»“æ„

```
LLMBayesian/
â”œâ”€â”€ ğŸ“‚ background/                # é¡¹ç›®èƒŒæ™¯æ–‡æ¡£
â”‚   â””â”€â”€ task.md                   # å®éªŒè®¡åˆ’å’Œè¿›åº¦è¿½è¸ª
â”œâ”€â”€ ğŸ“‚ results/                   # å®éªŒç»“æœå­˜å‚¨
â”‚   â”œâ”€â”€ experiment_results.json   # åˆæˆæ•°æ®å®éªŒç»“æœ
â”‚   â””â”€â”€ real_network_results.json # çœŸå®ç½‘ç»œæµ‹è¯•ç»“æœ
â”œâ”€â”€ ğŸ“‚ tests/                     # æµ‹è¯•è„šæœ¬
â”‚   â”œâ”€â”€ run_experiment.py         # è¿è¡Œåˆæˆæ•°æ®å®éªŒ
â”‚   â””â”€â”€ test_real_networks.py     # æµ‹è¯•çœŸå®è´å¶æ–¯ç½‘ç»œ
â”œâ”€â”€ ğŸ“‚ utils_set/                 # æ ¸å¿ƒåŠŸèƒ½æ¨¡å—
â”‚   â”œâ”€â”€ stat_translator.py        # ç»Ÿè®¡ç‰¹å¾ -> è‡ªç„¶è¯­è¨€å™äº‹ï¼ˆæ”¯æŒ HSICï¼‰
â”‚   â”œâ”€â”€ data_generator.py         # åˆæˆå› æœæ•°æ®ç”Ÿæˆå™¨
â”‚   â”œâ”€â”€ causal_reasoning_engine.py # ç«¯åˆ°ç«¯æ¨ç†å¼•æ“
â”‚   â”œâ”€â”€ prompts.py                # Prompt æ¨¡æ¿åº“ï¼ˆSherlock Holmes é£æ ¼ï¼‰
â”‚   â”œâ”€â”€ causal_inference_schema.py # Pydantic å“åº”æ¨¡å‹
â”‚   â””â”€â”€ utils.py                  # é…ç½®åŠ è½½å·¥å…·
â”œâ”€â”€ ğŸ“‚ llms/                      # LLM ç®¡ç†ç³»ç»Ÿ
â”‚   â”œâ”€â”€ manager.py                # LLM ç®¡ç†å™¨
â”‚   â”œâ”€â”€ config.yaml               # æ¨¡å‹é…ç½®ï¼ˆæ”¯æŒ OpenAI/ZhipuAI/ModelScopeï¼‰
â”‚   â”œâ”€â”€ base.py                   # LLM åŸºç±»
â”‚   â””â”€â”€ providers/                # å„æä¾›å•†å®ç°
â”œâ”€â”€ README.md                     # æœ¬æ–‡ä»¶
â”œâ”€â”€ MODIFICATION_SUMMARY.md       # æœ€æ–°ä¿®æ”¹æ€»ç»“
â””â”€â”€ PROJECT_STRUCTURE.md          # è¯¦ç»†é¡¹ç›®ç»“æ„è¯´æ˜
```

ğŸ’¡ **è¯¦ç»†çš„æ–‡ä»¶ç»„ç»‡è¯´æ˜è¯·å‚è§** [`PROJECT_STRUCTURE.md`](./PROJECT_STRUCTURE.md)

---

## ğŸ§ª å®éªŒç»“æœ

### åˆæˆæ•°æ®é›† (Synthetic Data)
- **å‡†ç¡®ç‡**: **66.7% (2/3)** å› æœæ¡ˆä¾‹
- âœ… **LiNGAM** (çº¿æ€§éé«˜æ–¯): æ­£ç¡®
- âœ… **Reverse** (åå‘å› æœ): æ­£ç¡®ï¼ˆé€šè¿‡ååº¦ + LiNGAM åŸç†è§£å†³ï¼‰
- âŒ **ANM** (éçº¿æ€§): é¢„æµ‹é”™è¯¯ï¼ˆç‰¹å®šåˆ†å¸ƒä¸‹çš„æŒ‘æˆ˜ï¼‰
- âœ… **Confounder/Independent**: æ­£ç¡®è¯†åˆ«ä¸º Unclear

### çœŸå®ä¸–ç•Œæ•°æ® (Real-World Benchmarks)
- **Asia ç½‘ç»œ** (ç¦»æ•£å˜é‡): **80% (4/5)** ğŸ‰
  - æˆåŠŸè¯†åˆ«: `smoke->lung`, `tub->either`, `either->xray`, `bronc->dysp`
  - å¤±è´¥: `either->dysp`
- **Sprinkler ç½‘ç»œ** (ç¦»æ•£å˜é‡): 0% (è°¨æ…è¿”å› Unclear)

### å…³é”®å‘ç°
1. **äº’ä¿¡æ¯ (MI) çš„å¨åŠ›**: ç›¸æ¯” Pearson ç›¸å…³ï¼ŒMI èƒ½æ›´å¥½åœ°æ•æ‰éçº¿æ€§æ®‹å·®ä¾èµ–ã€‚
2. **è¾¹é™…ç†µ** å¯¹ç¦»æ•£å˜é‡åˆ¤æ–­æœ‰æ˜¾è‘—è´¡çŒ®ï¼ˆAsia ä» 60% æå‡è‡³ 80%ï¼‰ã€‚
3. **LLM æ¨ç†èƒ½åŠ›**: LLM èƒ½å¤Ÿåœ¨å¤æ‚çš„å¤šç»´è¯æ®ä¸­è¿›è¡Œæƒè¡¡ï¼Œå±•ç°å‡ºç±»ä¼¼äººç±»ä¸“å®¶çš„æ¨ç†èƒ½åŠ›ã€‚

---

## ğŸ”§ ä½¿ç”¨ç¤ºä¾‹

### 1. è¿è¡Œå®Œæ•´å®éªŒ
```bash
cd tests
python run_experiment.py --model gpt-4-turbo --samples 1000
```

### 2. æµ‹è¯•çœŸå®ç½‘ç»œ
```bash
cd tests
python test_real_networks.py
```

### 3. ä»£ç é›†æˆç¤ºä¾‹

**ç”Ÿæˆæ•°æ®**ï¼š
```python
from utils_set.data_generator import CausalDataGenerator

generator = CausalDataGenerator(random_seed=42)
datasets = generator.generate_batch(n_samples=500)
```

**åˆ†æå•ä¸ªæ•°æ®å¯¹**ï¼š
```python
from utils_set.stat_translator import StatTranslator

translator = StatTranslator()
stats = translator.analyze(X, Y)
narrative = translator.generate_narrative(stats)
print(narrative)
```

**ä½¿ç”¨ LLM æ¨ç†**ï¼š
```python
from utils_set.causal_reasoning_engine import CausalReasoningEngine

engine = CausalReasoningEngine(model_name="deepseek-chat")
results = engine.run_experiment(datasets, save_results=True)
```

### 4. åˆ‡æ¢ LLM æ¨¡å‹
æ–¹æ³• 1 - ä¿®æ”¹é…ç½®æ–‡ä»¶ `llms/config.yaml`ï¼š
```yaml
used_model: "gpt-4-turbo"
```

æ–¹æ³• 2 - å‘½ä»¤è¡ŒæŒ‡å®šï¼š
```bash
cd tests
python run_experiment.py --model "gpt-4-turbo"
```

æ–¹æ³• 3 - ä»£ç ä¸­æŒ‡å®šï¼š
```python
engine = CausalReasoningEngine(model_name="gpt-4-turbo")
```

---

## ğŸ“Š æ•°æ®é›†ç±»å‹

### åˆæˆæ•°æ®é›†ï¼ˆå·²å®ç°ï¼‰
1. **LiNGAM**: çº¿æ€§éé«˜æ–¯åŠ æ€§å™ªå£° (`A -> B: B = 0.8A + uniform_noise`)
2. **ANM**: éçº¿æ€§åŠ æ€§å™ªå£° (`A -> B: B = tanh(A) + 0.5*cos(A) + noise`)
3. **Confounder**: æ··æ‚å› ç´  (`Z -> A, Z -> B`)
4. **Independent**: ç»Ÿè®¡ç‹¬ç«‹ (`A âŠ¥ B`)
5. **Reverse**: åå‘å› æœ (`B -> A`)

### çœŸå®æ•°æ®é›†ï¼ˆè§„åˆ’ä¸­ï¼‰
- bnlearn ç»å…¸ç½‘ç»œï¼šSprinkler, Asia, Alarm
- Tubingen Cause-Effect Pairs

---

## ğŸ§  Prompt è®¾è®¡

### Sherlock Holmes Prompt
```
ä½ æ˜¯ä¸€ä½ç²¾é€šç»Ÿè®¡å­¦å’Œå› æœæ¨ç†çš„ä¾¦æ¢...

## ç»Ÿè®¡åˆ†ææŠ¥å‘Š
{narrative}

## æ¨ç†è¦æ±‚
åŸºäº LiNGAM å’Œ ANM åŸç†ï¼Œåˆ¤æ–­å› æœæ–¹å‘...
```

æ”¯æŒå¤šç§æ¨¡æ¿ï¼š
- `sherlock`: å®Œæ•´ç‰ˆï¼ˆé»˜è®¤ï¼‰
- `simple`: ç®€åŒ–ç‰ˆ
- `residual_only`: æ¶ˆèç ”ç©¶ï¼ˆä»…æ®‹å·®ä¿¡æ¯ï¼‰

---

## ğŸ› ï¸ é…ç½®

### LLM æ¨¡å‹é…ç½® (`llms/config.yaml`)
```yaml
models:
  text_models:
    - name: "deepseek-chat"
      provider: "openai"
      api_key: "your-api-key"
      base_url: "https://api.example.com/v1"
      temperature: 0.7
```

æ”¯æŒçš„æä¾›å•†ï¼š
- OpenAI (GPT-4, GPT-3.5)
- ZhipuAI (GLM-4)
- ModelScope (Qwen, DeepSeek-V3, MiniMax)

---

## ğŸ“ˆ ä¸‹ä¸€æ­¥å·¥ä½œ

### çŸ­æœŸ
- [ ] åœ¨ StatTranslator ä¸­åŠ å…¥éçº¿æ€§æ‹Ÿåˆï¼ˆGAMã€å¤šé¡¹å¼ï¼‰
- [ ] ä½¿ç”¨ bnlearn çœŸå®ç½‘ç»œè¿›è¡Œæµ‹è¯•
- [ ] æ¶ˆèç ”ç©¶ï¼šä¸åŒ Prompt å’Œæ¨¡å‹çš„å½±å“

### ä¸­æœŸ
- [ ] å®ç°åŸºå‡†ç®—æ³•ï¼ˆPC, GES, æ ‡å‡† LiNGAMï¼‰è¿›è¡Œå¯¹æ¯”
- [ ] å®ç°è¾›æ™®æ£®æ‚–è®ºæ£€æµ‹ï¼ˆæ··æ‚å› ç´ è¯†åˆ«ï¼‰
- [ ] å®Œæ•´çš„è¯„ä¼°æŒ‡æ ‡ï¼ˆPrecision, Recall, F1, AUROCï¼‰

### é•¿æœŸ
- [ ] å®ç°"å…ƒè®¤çŸ¥ä»²è£"æœºåˆ¶ï¼ˆåˆ›æ–°ç‚¹2ï¼‰
- [ ] åœ¨å¤§è§„æ¨¡çœŸå®æ•°æ®é›†ä¸ŠéªŒè¯
- [ ] æ’°å†™è®ºæ–‡å¹¶æŠ•ç¨¿

---

## ğŸ“ è®ºæ–‡è¿›åº¦

è¯¦è§ [task.md](task.md)

**å½“å‰é˜¶æ®µ**: ç¬¬ä¸‰é˜¶æ®µå·²å®Œæˆï¼Œè¿›å…¥ç¬¬å››é˜¶æ®µï¼ˆè¯„ä¼°ä¸åˆ†æï¼‰

---

## ğŸ¤ è´¡çŒ®

æ¬¢è¿æäº¤ Issue å’Œ Pull Requestï¼

---

## ğŸ“„ è®¸å¯è¯

MIT License

---

## ğŸ™ è‡´è°¢

- bnlearn: https://github.com/erdogant/bnlearn
- LiNGAM ç†è®º: Shimizu et al. (2006)
- ANM ç†è®º: Hoyer et al. (2009)
